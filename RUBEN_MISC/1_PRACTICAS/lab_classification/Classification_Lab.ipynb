{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada593d9",
   "metadata": {
    "id": "ada593d9",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc": true
   },
   "source": [
    "# Laboratory exercise: Classification\n",
    "\n",
    "In this laboratory exercise we will apply classification and regression algorithms over a synthetic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bfad0d",
   "metadata": {},
   "source": [
    "\n",
    "## Data load.\n",
    "\n",
    "Load the data variables from the npz file provided with this exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c450bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "\n",
    "# Load data from file 10012345.mat .\n",
    "data = np.load('10012345.npz')\n",
    "\n",
    "xRtrain = data['xRtrain']\n",
    "xRtrainLost = data['xRtrainLost']\n",
    "xRval = data['xRval']\n",
    "sRtrain = data['sRtrain']\n",
    "sRval = data['sRval']\n",
    "xCtrain = data['xCtrain']\n",
    "xCval = data['xCval']\n",
    "yCtrain = data['yCtrain']\n",
    "yCval = data['yCval']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ad414",
   "metadata": {},
   "source": [
    "Initialize all requested variables to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53117023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification:\n",
    "w_full, e_full, p20, emin, nvar, wmin, cv0, rp_opt, fpr = 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "# Regression:\n",
    "wML, AAE, NLL, wmean, Vw = 0, 0, 0, 0, 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2482c9af",
   "metadata": {},
   "source": [
    "## Part 1: Clasification\n",
    "\n",
    "Each of the data matrices `xCtrain` and `xCval` contains 240 data vectors with dimension $D=5$. \n",
    "\n",
    "Assume that the binary labels `yCtrain` and `yCval` (with values in {0, 1}) were generated according to a logistic regression model:\n",
    "$$p(y = 1 | {\\bf w}, {\\bf x}) = \\frac{1}{1 + \\exp(-{\\bf w}^T {\\bf z})}$$\n",
    "where  \n",
    "$$\n",
    "{\\bf z} = \\begin{pmatrix} 1 \\\\ {\\bf x} \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4644ab3f",
   "metadata": {},
   "source": [
    "### Exercise C0 [extra]:\n",
    "\n",
    "Normalize the input matrices in such a way that each feature has zero mean and unit standard deviation. You can do it using standard python commands or by means of the `preprocessing.StandardScaler` from `sklearn`. Use `xCtrain` to estimate the mean and variance of each feature, and make sure that the same normalization is applied to any input, ${\\bf x}$, no matter if it belogs to the training or the validation set.\n",
    "\n",
    "Store the normalized matrices in the same variables, `xCtrain`and `xCval`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99a10e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 5)\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.\n",
    "# <SOL>\n",
    "# </SOL>    \n",
    "# mean_R = np.mean(xRtrain, axis=0)\n",
    "# std_R = np.std(xRtrain, axis=0)\n",
    "# Xtrain = (xRtrain - mean_R) / std_R\n",
    "# xRtrainLost = (xRtrainLost - mean_R) / std_R\n",
    "# xRval = (xRval - mean_R) / std_R\n",
    "\n",
    "# mean_R = np.mean(xRtrain, axis=0)\n",
    "# std_R = np.std(xRtrain, axis=0)\n",
    "# XCrain = (xCtrain - mean_R) / std_R\n",
    "# xCval = (xCval - mean_R) / std_R\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler2 = StandardScaler()\n",
    "# Fit the scaler to the training data and transform it\n",
    "xCtrain_norm = scaler.fit_transform(xCtrain)\n",
    "xRtrain = scaler2.fit_transform(xRtrain)\n",
    "\n",
    "# You can use the same scaler to normalize any validation set to ensure consistency\n",
    "xCval_norm= scaler.transform(xCval)  # Replace with your validation data\n",
    "xRval = scaler2.transform(xRval)\n",
    "\n",
    "xCtrain = np.hstack((np.ones((xCtrain_norm.shape[0], 1)), xCtrain_norm))\n",
    "xCval = np.hstack((np.ones((xCval_norm.shape[0], 1)), xCval_norm))\n",
    "\n",
    "print(xCtrain_norm.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d726bc8",
   "metadata": {},
   "source": [
    "### Exercise C1:\n",
    "\n",
    "As a preliminary task, fit a logistic regression model using the training data available in `xCtrain` and `yCtrain`, using the implementation available from `sklearn`. Use regularization parameter $C=2$, set the `random_state` to 42 and use the default values for all other arguments. \n",
    "\n",
    "Store the resulting weight vector in the variable `w_full`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c86139e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02930159 -0.12589863  1.15997047 -0.15528534  0.71331906  0.27936377]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.\n",
    "\n",
    "#<SOL>\n",
    "#</SOL>\n",
    "model = LogisticRegression(C=2, random_state=42, fit_intercept=False)\n",
    "w_full = model.fit(xCtrain, yCtrain).coef_[0]#Porque es binario\n",
    "print(w_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede95aeb",
   "metadata": {},
   "source": [
    "### Exercise C2.\n",
    "\n",
    "Determine the classification error rate measured on the validation data (`xCval` and `yCval`). Store the error rate in the variable `e_full`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54ac4c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25104166666666666\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.\n",
    "#<SOL>\n",
    "# </SOL>\n",
    "# Predecir las etiquetas para los datos de validación\n",
    "yCval_pred = model.predict(xCval)\n",
    "\n",
    "# Calcular la tasa de error de clasificación\n",
    "e_full = np.mean(yCval_pred != yCval)\n",
    "# Print the error rate.\n",
    "print(e_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2e19d2",
   "metadata": {},
   "source": [
    "### Exercise C3\n",
    "\n",
    "Determine the probability that the $k$-th sample in the validation set belongs to category  $y_k = 1$, according to the model computed in exercise 1, for $k = 0, 1, \\dots, 19$. Store the result in the variable `p20`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6647046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88394365 0.28847106 0.08091301 0.0258122  0.87142269 0.84381446\n",
      " 0.19677792 0.33481932 0.41210246 0.23977197 0.23093801 0.41438111\n",
      " 0.15926061 0.16408098 0.86420816 0.19535421 0.28271016 0.28848939\n",
      " 0.02786647 0.39428892]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "# <SOL>\n",
    "# </SOL>\n",
    "K = 20\n",
    "\n",
    "probas = model.predict_proba(xCval)\n",
    "\n",
    "probas_y1 = probas[:, 1]\n",
    "p20 = probas_y1[:20]  \n",
    "\n",
    "\n",
    "# Print the probabilities.\n",
    "print(p20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184ca46b",
   "metadata": {},
   "source": [
    "### Exercise C4.\n",
    "\n",
    "It is known that all coefficients  $w_i$  (with  $i > n$) are zero, that is, all variables $x_{n+1}, \\dots, x_{D-1}$ are irrelevant for the classification task, but the value of $n$ is unknown. Consequently, the goal is to fit a model that includes only the relevant variables:\n",
    "\n",
    "Train $D$ different logistic regression models, starting with the model that uses only the first variable, and adding one variable at a time, so that the $i$-th model will use only the variables $x_0, x_1, \\dots, x_{i-1}$.  Using $C=2$, `random_state`=42 and all other default parameters.\n",
    "\n",
    "For each model, compute the classification error rate (on the validation data), and keep the best result. \n",
    "\n",
    "Store the following variables:\n",
    "\n",
    "  * `emin`: the lowest validation error\n",
    "  * `nvar`: an integer indicating the number of variables in the model, \n",
    "  * `wmin`: the corresponding weight vector (only for the best case).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "619dbdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4864583333333333\n",
      "0.4697916666666667\n",
      "0.2833333333333333\n",
      "0.2822916666666667\n",
      "0.2510416666666667\n",
      "0.2510416666666667\n",
      "emin = 0.2510416666666667\n",
      "nvar = 5\n",
      "[ 0.03084771 -0.13571241  1.16055007 -0.15423423  0.7210371 ]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.\n",
    "#<SOL>\n",
    "#</SOL>\n",
    "\n",
    "emin = float('inf') \n",
    "nvar = 0              \n",
    "wmin = None           \n",
    "\n",
    "D = xCtrain.shape[1] \n",
    "\n",
    "for i in range(1, D + 1):  \n",
    "    x_train_subset = xCtrain[:, :i]\n",
    "    x_val_subset = xCval[:, :i]\n",
    "\n",
    "    model = LogisticRegression(C=2, random_state=42, fit_intercept=False)\n",
    "    model.fit(x_train_subset, yCtrain)\n",
    "\n",
    "    y_val_pred = model.predict(x_val_subset)\n",
    "\n",
    "    error_rate = 1 - model.score(x_val_subset, yCval)  \n",
    "    print(error_rate)\n",
    "    if error_rate < emin:\n",
    "        emin = error_rate\n",
    "        nvar = i\n",
    "        wmin = model.coef_[0]  # Guardar el vector de pesos\n",
    "\n",
    "# Print the results.\n",
    "print(f\"emin = {emin}\")\n",
    "print(f\"nvar = {nvar}\")\n",
    "print(wmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa77badb",
   "metadata": {},
   "source": [
    "### Exercise C5 [extra].\n",
    "\n",
    "In this exercise we will train a classifier based on **quadratic discriminant analysis**, using the appropriate class from `sklearn`.\n",
    "\n",
    "The algorithm has a regularization parameter, `reg_param`, that must take some value between 0 and 1. We will select the appropriate value by means of 10-fold cross validation. As a validation metric, we will use the <a href=https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score>F1-score</a>.\n",
    "\n",
    "To do so:\n",
    "\n",
    "  1. Join the train and validation sets into a single dataset, by stacking matrices `xCtrain` (on top) and `xCval` (down) into a single matrix `xCV`. In a similar way, join labels into aarray `yV`.\n",
    "  2. Using the CV dataset and the `cross_val_score` method from `sklearn.model_selection`, compute the cross validation F1-score (averaged over all folds), for `reg_param=0`. Save the result in variable `cv0`\n",
    "  3. Select the best value of `reg_param` in $\\{0, 0.1, 0.2, 0.3, \\ldots, 1.0\\}$ by 10-fold cross validation, according to the F1-score. Save the result in variable `rp_opt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "de4906ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 6)\n",
      "(240,)\n",
      "(1200,)\n",
      "0.0\n",
      "0.0\n",
      "0.1\n",
      "0.7520529343472969\n",
      "0.2\n",
      "0.7514244975837462\n",
      "0.30000000000000004\n",
      "0.7500788396669354\n",
      "0.4\n",
      "0.750061549997822\n",
      "0.5\n",
      "0.7506710738073459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:975: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:975: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:975: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:975: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:975: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:975: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:975: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:975: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:975: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:975: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:975: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:975: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:975: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:975: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:975: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:975: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:975: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:975: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:975: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:972: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:975: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6000000000000001\n",
      "0.7526142888404695\n",
      "0.7000000000000001\n",
      "0.7539991221650565\n",
      "0.8\n",
      "0.7560250868037961\n",
      "0.9\n",
      "0.7570186351908927\n",
      "1.0\n",
      "0.7539671338617968\n",
      "cv0 = 0.0\n",
      "rp_opt = 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.\n",
    "#<SOL>\n",
    "#</SOL>\n",
    "# print(xCtrain.size)\n",
    "# print(len(xCtrain))\n",
    "# print(xCval.size)\n",
    "# print(len(yCtrain))\n",
    "import sklearn.metrics\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "model = QuadraticDiscriminantAnalysis(reg_param=0)\n",
    "xCV = np.vstack((xCtrain,xCval))\n",
    "yV = np.hstack((yCtrain,yCval))\n",
    "scorer = make_scorer(f1_score)\n",
    "cv0 = np.mean(cross_val_score(model, xCV, yV, cv = 10, scoring = scorer))\n",
    "\n",
    "best_score = -np.inf  \n",
    "rp_opt = 0 \n",
    "\n",
    "for rp in np.arange(0,1.1,0.1):\n",
    "    model = QuadraticDiscriminantAnalysis(reg_param=rp)\n",
    "    cv_score = np.mean(cross_val_score(model, xCV, yV, cv = 10, scoring = scorer))\n",
    "    print(rp)\n",
    "    print(cv_score)\n",
    "    if cv_score > best_score:\n",
    "        best_score = cv_score\n",
    "        rp_opt = rp\n",
    "\n",
    "# Print the results.\n",
    "print(f\"cv0 = {cv0}\")\n",
    "print(f\"rp_opt = {rp_opt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed6926",
   "metadata": {},
   "source": [
    "### Exercise C6 [extra].\n",
    "\n",
    "Take the regularization parameter selected in C5, train the quadratic discriminant using `xCtrain`and `yCtrain`, and compute the false positive rate (i.e. the ratio of false positives vs the total number of negatie samples) of the classifier over the validation set. Save the result in variable `fpr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb6d984b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[343 124]\n",
      " [117 376]]\n",
      "0.26552462526766596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ruben\\anaconda3\\envs\\Tratamientodedatos\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code here.\n",
    "#<SOL>\n",
    "#</SOL>\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "model = QuadraticDiscriminantAnalysis(reg_param=rp_opt)\n",
    "model.fit(xCtrain,yCtrain)\n",
    "y_pred = model.predict(xCval)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(yCval, y_val_pred).ravel()\n",
    "print(confusion_matrix(yCval, y_val_pred))\n",
    "# Calcular la tasa de falsos positivos (False Positive Rate, FPR)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "# Print the false positive rate.\n",
    "print(fpr)\n",
    "\n",
    "cm = confusion_matrix(yCval, y_val_pred)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "\n",
    "# Añadir etiquetas y título\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Real')\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f0d800",
   "metadata": {},
   "source": [
    "## Part 2: Regression\n",
    "\n",
    "The mentioned variables include a training set consisting of 300 data points, each consisting of input-output pairs:  $D = \\{{\\bf x}_k, s_k\\}_{k=0}^{299}$. The input vectors are provided as the rows of the variable `xRtrain`, while their corresponding labels are available in the vector `sRtrain`. Use these variables as provided, without applying any normalization procedure.\n",
    "\n",
    "Assume the data were generated according to the following model:\n",
    "$$\n",
    "s = w_0 + w_1 x_0 + w_2 x_2^3 + w_3 \\exp(x_4) + \\varepsilon\n",
    "$$\n",
    "where the noise samples follow a Gaussian distribution with zero mean and variance $\\sigma^2_{\\varepsilon} = 0.4$.\n",
    "\n",
    "### Exercise R1\n",
    "\n",
    "Obtain the maximum likelihood estimator of the model. Store your result in the variable `wML`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e58bc2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 5)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xRtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2e8b89e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.22827806  0.19852257  0.01735276  0.04003244]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.\n",
    "#<SOL>\n",
    "#</SOL>\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "l = len(xRtrain)\n",
    "x0 = xRtrain[:, 0]\n",
    "x2 = xRtrain[:, 2]**3\n",
    "x4 = np.exp(xRtrain[:, 4])\n",
    "\n",
    "Z = np.column_stack((np.ones(l), x0, x2, x4))\n",
    "\n",
    "\n",
    "model = LinearRegression(fit_intercept=False) #sE PUEDE HACER POR FORMULA\n",
    "model.fit(Z, sRtrain)\n",
    "\n",
    "\n",
    "wML = model.coef_\n",
    "\n",
    "# Se puede hacer también por minimos cuadrados\n",
    "# wML = np.linalg.lstsq(Z, sRtrain)[0]\n",
    "\n",
    "# Print the result.\n",
    "print(wML)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1605e8",
   "metadata": {},
   "source": [
    "### Exercise R2\n",
    "\n",
    "For the previously obtained estimator, determine the average absolute error on the training dataset, i.e.,\n",
    "$$\n",
    "\\text{AAE} = \\frac{1}{N} \\sum_{i=1}^{N} |s(i) - \\hat{s}(i)|\n",
    "$$\n",
    "where  N  is the number of training data points. Store your result in the variable AAE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6db68be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8177666501366135\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.\n",
    "#<SOL>\n",
    "#</SOL>\n",
    "s_train_pred = Z.dot(wML)\n",
    "\n",
    "N = len(sRtrain) \n",
    "AAE = np.sum(np.abs(sRtrain - s_train_pred)) / N\n",
    "# Print the result.\n",
    "print(AAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fbd634",
   "metadata": {},
   "source": [
    "### Exercise R3\n",
    "\n",
    "Compute the negative log-likelihood,  of the previously obtained estimator using the training data, and store the result in the variable `NLL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9c2c6b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310.7184613636165\n",
      "388.3980767045206\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.\n",
    "#<SOL>\n",
    "#</SOL>\n",
    "K = len(sRtrain)\n",
    "d = sRtrain-np.dot(Z, wML)\n",
    "\n",
    "print(np.dot(d, d))\n",
    "sigma_eps = np.sqrt(0.4)\n",
    "print(np.dot(d, d) / (2*sigma_eps**2))\n",
    "LL = - K/2*np.log(2*np.pi*sigma_eps**2) - np.dot(d, d) / (2*sigma_eps**2)\n",
    "print(NLL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a5cf57",
   "metadata": {},
   "source": [
    "### Exercise R4\n",
    "\n",
    "Assume that the weight vector ${\\bf w}$  has a prior distribution  $p_W({\\bf w})$ , which is Gaussian with zero mean, unit variances ($\\text{var}\\{w_i\\} = 1$), and covariances $\\text{cov}\\{w_i, w_j\\} = 0.5$,  $i \\neq j$. \n",
    "\n",
    "Compute the posterior mean and the posterior covariance matrix of ${\\bf w}$ . Store your results in the variables `wmean` and `Vw`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b99f8",
   "metadata": {},
   "source": [
    "La media posterior \\( \\mathbf{w}_{\\text{mean}} \\) y la matriz de covarianza posterior \\( V_w \\) se calculan de la siguiente manera:\n",
    "\n",
    "1. **Matriz de covarianza posterior**:\n",
    "   $\n",
    "   V_w = \\left( \\frac{1}{\\sigma^2} X^T X + \\Sigma^{-1} \\right)^{-1}\n",
    "   $\n",
    "\n",
    "2. **Media posterior**:\n",
    "   $\n",
    "   \\mathbf{w}_{\\text{mean}} = V_w \\left( \\frac{1}{\\sigma^2} X^T \\mathbf{s} + \\Sigma^{-1} \\mathbf{w}_0 \\right)\n",
    "   $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9ac08e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[ 1.71723112e-03 -5.50058769e-05 -3.09101298e-07 -2.21149075e-04]\n",
      " [-5.50058769e-05  1.34195844e-03 -1.61350313e-05  3.21553783e-05]\n",
      " [-3.09101298e-07 -1.61350313e-05  7.61683135e-05 -1.21757617e-06]\n",
      " [-2.21149075e-04  3.21553783e-05 -1.21757617e-06  1.26486310e-04]]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.\n",
    "#<SOL>\n",
    "#</SOL>\n",
    "\n",
    "N = len(sRtrain)  # Número de puntos de datos\n",
    "sigma_squared = 0.4  # Varianza del ruido\n",
    "\n",
    "# 1. Definir la matriz de covarianza\n",
    "covariance = 0.5\n",
    "Vw = np.full((4, 4), covariance)\n",
    "np.fill_diagonal(Vw, 1)\n",
    "\n",
    "\n",
    "w0 = np.zeros(4)  # Media a priori\n",
    "\n",
    "\n",
    "XTX_inv = np.linalg.inv((1/sigma_squared) * np.dot(Z.T, Z) + np.linalg.inv(Vw))\n",
    "Vw = XTX_inv\n",
    "\n",
    "w_mean = np.dot(Vw, (1/sigma_squared) * np.dot(Z.T, sRtrain) + np.dot(np.linalg.inv(Vw), w0))\n",
    "\n",
    "# Print the results.\n",
    "print(wmean)\n",
    "print(Vw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f17baac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########################################\n",
    "# Save results in file results.npz\n",
    "np.savez('results.npz',\n",
    "         w_full=w_full, e_full=e_full, p20=p20, emin=emin, nvar=nvar,\n",
    "         cv0=cv0, rp_opt=rp_opt, fpr=fpr, xCtrain=xCtrain, xCval=xCval,\n",
    "         wmin=wmin, wML=wML, AAE=AAE, NLL=NLL, wmean=wmean, Vw=Vw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52502dbf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Hand_Digit_with_NN_professor.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Tratamientodedatos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
